#!/bin/bash
exec scala -cp qry.jar:test/src/test_client.jar:src/naturalli_client.jar "$0" "$@"
!#
import Qry._

val SNLI_TRAIN = "etc/snli/snli_1.0rc3_train.tab"
val SNLI_TEST = "etc/snli/snli_1.0rc3_dev.tab"

val SICK_TRAIN = "etc/sick/sick_train.tab"
val SICK_SNLI_TRAIN = "etc/sick/sick+snli_train.tab"
val SICK_TEST = "etc/sick/sick_dev.tab"

val RTE_TRAIN = "etc/RTE-3/English_dev.tab"
val RTE_SNLI_TRAIN = "etc/sick/rte+snli_train.tab"
val RTE_TEST = "etc/RTE-3/English_dev.tab"

//
// Remove potentially stale caches
//
submit("rm" ->(SNLI_TRAIN + ".SIMPLE.cache"))
submit("rm" ->(SNLI_TEST + ".SIMPLE.cache"))

//
// Define the program
//
def program(memoryMB:Int):List[String] = ("java"
  -('cp, cp)
//	-"Xrunhprof:cpu=samples,depth=25"
	-("Xmx" + memoryMB + "M")
	-"Xss32m"
  -"XX:MaxPermSize=256M"
  -"Dwordnet.database.dir=etc/WordNet-3.1/dict"
	-'server
  -'ea
	->"edu.stanford.nlp.naturalli.entail.ClassifierTrainer"
  -("classifier", "SIMPLE")
  -("naturalli_search", "/dev/null")
).toList

using("run_test/")

//
// Warm up the cache
//
submit(program(16000)
  -("train.file", SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SNLI_TEST)
  -("test.cache.do", "true")

  -("model", touch("model.ser.gz"))
  -("features", """[ OVERLAP  POS_OVERLAP ]""" )  // just minimal features to heat up the POS tagger
  -("features.nolex", "false")
  
  -("parallel", "true")
  
  -("log.file", touch("redwood.log"))
)

//
// Run the learning curve
//
parallel(8) submit(program(8500)
  -("train.file", SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SNLI_TEST)
  -("test.cache.do", "true")

  -("train.count", "10" & "100" & "1000" & "10000" & "50000" & "100000" & "250000" & "1000000")
  -("model", touch("model.ser.gz"))
  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" )
  -("features.nolex", "true" & "false")

  -("parallel", "false")
  
  -("log.file", touch("redwood.log"))
)

//
// Run the unigram learning curve
//
parallel(8) submit(program(8500)
  -("train.file", SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SNLI_TEST)
  -("test.cache.do", "true")

  -("train.count", "10" & "100" & "1000" & "10000" & "50000" & "100000" & "250000" & "1000000")
  -("model", touch("model.ser.gz"))
  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM ]""" )
  -("features.nolex", "false")

  -("parallel", "false")
  
  -("log.file", touch("redwood.log"))
)

//
// Try out other features
//
parallel(4) submit(program(15000)
  -("train.file", SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SNLI_TEST)
  -("test.cache.do", "true")

  -("train.count", "1000000")
  -("model", touch("model.ser.gz"))
  -("features", 
      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" &
      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ENTAIL_TRIGRAM ]""" &
      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ENTAIL_BOTH_GRAM ]""" &
      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ENTAIL_TRIGRAM ENTAIL_BOTH_GRAM ]"""
      )
  -("features.nolex", "false")
  -("parallel", "false")
  -("log.file", touch("redwood.log"))
)

//
// Run ablation studies with keyword features
//
parallel(1) submit(program(70000)
  -("train.file", SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SNLI_TEST)
  -("test.cache.do", "true")

  -("train.count", "10" & "100" & "1000" & "10000" & "50000" & "100000" & "250000" & "1000000")
  -("model", touch("model.ser.gz"))
  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM  KEYWORD_OVERLAP  ENTAIL_KEYWORD ]""" )
  -("features.nolex", "true" & "false")

  -("parallel", "false")
  
  -("log.file", touch("redwood.log"))
)

//
// Run the SICK data
//
parallel(8) submit(program(8500)
  -("train.file", SICK_TRAIN & SNLI_TRAIN & SICK_SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SICK_TEST)
  -("test.cache.do", "true")

  -("train.count", "10000")
  -("model", touch("model.ser.gz"))
  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" )
  -("features.nolex", "true" & "false")

  -("parallel", "false")
  
  -("log.file", touch("redwood.log"))
)

//
// Run the RTE data
//
parallel(8) submit(program(8500)
  -("train.file", RTE_TRAIN & SNLI_TRAIN & RTE_SNLI_TRAIN)
  -("train.cache.do", "true")
  -("test.file", SICK_TEST)
  -("test.cache.do", "true")

  -("train.count", "10000")
  -("model", touch("model.ser.gz"))
  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" )
  -("features.nolex", "true" & "false")

  -("parallel", "false")
  
  -("log.file", touch("redwood.log"))
)


def cp:String = {
  val JAVANLP = List(
    System.getenv("JAVANLP_HOME") + "/projects/core/classes",
    System.getenv("JAVANLP_HOME") + "/projects/core/lib/joda-time.jar",
    System.getenv("JAVANLP_HOME") + "/projects/core/lib/jollyday-0.4.7.jar",
    System.getenv("JAVANLP_HOME") + "/projects/core/lib/protobuf.jar",
    System.getenv("JAVANLP_HOME") + "/projects/more/classes",
    System.getenv("JAVANLP_HOME") + "/projects/more/lib/BerkeleyParser.jar",
    System.getenv("JAVANLP_HOME") + "/projects/research/classes",
    System.getenv("JAVANLP_HOME") + "/projects/research/lib/reverb.jar",
    System.getenv("JAVANLP_HOME") + "/projects/research/lib/postgresql.jar",
    "/u/nlp/data/StanfordCoreNLPModels/stanford-corenlp-models-current.jar",
    "/u/nlp/data/StanfordCoreNLPModels/stanford-corenlp-caseless-models-current.jar"
  ).mkString(":")
  val SCALA = List(
      System.getenv("SCALA_HOME") + "/lib/scala-library.jar",
      System.getenv("SCALA_HOME") + "/lib/config-1.2.0.jar",
      System.getenv("SCALA_HOME") + "/lib/scala-xml_2.11-1.0.1.jar"
    ).mkString(":")
  val CUSTOM = List(
      "lib/corenlp-scala.jar",
      "lib/trove.jar",
      "lib/jaws.jar",
      "lib/scripts/sim-1.0.jar",
      "lib/gson-2.3.1.jar",
      "lib/protobuf.jar"
    ).mkString(":")
  List("src/naturalli_preprocess.jar", JAVANLP, SCALA, CUSTOM).mkString(":")
}
