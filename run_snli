#!/bin/bash
exec scala -cp qry.jar:test/src/test_client.jar:src/naturalli_client.jar "$0" "$@"
!#
import Qry._

val SNLI_TRAIN = "etc/snli/snli_1.0rc3_train.tab"
val SNLI_DEV   = "etc/snli/snli_1.0rc3_dev.tab"
val SNLI_TEST  = "etc/snli/snli_1.0rc3_test.tab"

val SICK_TRAIN = "etc/sick/sick_train.tab"
val SICK_SNLI_TRAIN = "etc/sick/sick+snli_train.tab"
val SICK_TEST = "etc/sick/sick_test.tab"

val RTE_TRAIN = "etc/RTE-3/English_dev.tab"
val RTE_SNLI_TRAIN = "etc/sick/rte+snli_train.tab"
val RTE_TEST = "etc/RTE-3/English_dev.tab"


//
// Define the program
//
def program(memoryMB:Int):List[String] = ("java"
  -('cp, cp)
//	-"Xrunhprof:cpu=samples,depth=25"
	-("mx" + memoryMB + "M")
  -"Dwordnet.database.dir=etc/WordNet-3.1/dict"
	-'server
  -'ea
	->"edu.stanford.nlp.naturalli.entail.ClassifierTrainer"
  -("classifier", "SIMPLE")
  -("naturalli_search", "/dev/null")
  -("test.errors", touch("errors.txt"))
).toList

using("runs/")

parallel(13) submit(program(50000)
  -("train.file", SNLI_TRAIN)
  -("train.cache.do", "false")
  -("test.file", SNLI_DEV)
  -("test.cache.do", "false")

  -("train.count", "1000000")
  -("train.regularizer", "l1")
  -("train.sigma", "0.5" & "0.6" & "0.7" & "0.8" & "0.9" & 
                   "1.0" & "1.1" & "1.2" & "1.3" & "1.4" &
                   "1.5" & "1.6" & "1.7" & "1.8" & "1.9" & "2.0"
                   )
  -("train.align.maxlength", "4")
  -("train.align.mincount",  "0")
  
  -("vocab.threshold", "0")

  -("model", touch("model.ser.gz"))
  -("features", 
      """[ 
           BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  
           ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM  ENTAIL_BOTH_GRAM  
           KEYWORD_OVERLAP  
           DEPTREE_ROOT_STRUCTURE  ENTAIL_DEPTREE 
           MT_UNIGRAM  MT_PHRASE
         ]"""

  )
  -("features.nolex", "false")

  -("parallel", "false")
  -("threads",  "1")
  
  -("log.file", touch("redwood.log"))
)


////
//// Run the learning curve
////
//parallel(8) submit(program(8500)
//  -("train.file", SNLI_TRAIN)
//  -("train.cache.do", "false")
//  -("test.file", SNLI_TEST)
//  -("test.cache.do", "false")
//
//  -("train.count", "10" & "100" & "1000" & "10000" & "50000" & "100000" & "250000" & "1000000")
//  -("model", touch("model.ser.gz"))
//  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" )
//  -("features.nolex", "true" & "false")
//
//  -("parallel", "false")
//  
//  -("log.file", touch("redwood.log"))
//)
//
////
//// Run the unigram learning curve
////
//parallel(8) submit(program(8500)
//  -("train.file", SNLI_TRAIN)
//  -("train.cache.do", "false")
//  -("test.file", SNLI_TEST)
//  -("test.cache.do", "false")
//
//  -("train.count", "10" & "100" & "1000" & "10000" & "50000" & "100000" & "250000" & "1000000")
//  -("model", touch("model.ser.gz"))
//  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM ]""" )
//  -("features.nolex", "false")
//
//  -("parallel", "false")
//  
//  -("log.file", touch("redwood.log"))
//)

////
//// Try out other features
////
//parallel(2) submit(program(32000)
//  -("train.file", SNLI_TRAIN)
//  -("train.cache.do", "false")
//  -("test.file", SNLI_TEST)
//  -("test.cache.do", "false")
//
//  -("train.count", "1000000")
//  -("model", touch("model.ser.gz"))
//  -("features", 
////      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ENTAIL_BOTH_GRAM ]""" &
////      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ENTAIL_TRIGRAM ]""" &
////      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ENTAIL_TRIGRAM ENTAIL_BOTH_GRAM ]""" &
//      """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]"""
//      )
//  -("features.nolex", "false")
//  -("parallel", "false")
//  -("log.file", touch("redwood.log"))
//)

////
//// Run ablation studies with keyword features
////
//parallel(1) submit(program(70000)
//  -("train.file", SNLI_TRAIN)
//  -("train.cache.do", "false")
//  -("test.file", SNLI_TEST)
//  -("test.cache.do", "false")
//
//  -("train.count", "10" & "100" & "1000" & "10000" & "50000" & "100000" & "250000" & "1000000")
//  -("model", touch("model.ser.gz"))
//  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM  KEYWORD_OVERLAP  ENTAIL_KEYWORD ]""" )
//  -("features.nolex", "true" & "false")
//
//  -("parallel", "false")
//  
//  -("log.file", touch("redwood.log"))
//)
//
////
//// Run the SICK data
////
//parallel(8) submit(program(8500)
//  -("train.file", SICK_TRAIN & SNLI_TRAIN & SICK_SNLI_TRAIN)
//  -("train.cache.do", "false")
//  -("test.file", SICK_TEST)
//  -("test.cache.do", "false")
//
//  -("train.count", "10000")
//  -("model", touch("model.ser.gz"))
//  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" )
//  -("features.nolex", "true" & "false")
//
//  -("parallel", "false")
//  
//  -("log.file", touch("redwood.log"))
//)
//
////
//// Run the RTE data
////
//parallel(8) submit(program(8500)
//  -("train.file", RTE_TRAIN & SNLI_TRAIN & RTE_SNLI_TRAIN)
//  -("train.cache.do", "false")
//  -("test.file", SICK_TEST)
//  -("test.cache.do", "false")
//
//  -("train.count", "10000")
//  -("model", touch("model.ser.gz"))
//  -("features", """[ BLEU  LENGTH_DIFF  OVERLAP  POS_OVERLAP  ENTAIL_UNIGRAM  ENTAIL_BIGRAM  CONCLUSION_NGRAM ]""" )
//  -("features.nolex", "true" & "false")
//
//  -("parallel", "false")
//  
//  -("log.file", touch("redwood.log"))
//)


def cp:String = {
  val JAVANLP = List(
    System.getenv("JAVANLP_HOME") + "/projects/core/classes",
    System.getenv("JAVANLP_HOME") + "/projects/more/classes",
    "/u/nlp/data/StanfordCoreNLPModels/stanford-corenlp-models-current.jar",
    "/u/nlp/data/StanfordCoreNLPModels/stanford-corenlp-caseless-models-current.jar"
  ).mkString(":")
  val CUSTOM = List(
      "lib/corenlp-scala.jar",
      "lib/trove.jar",
      "lib/jaws.jar",
      "lib/scripts/sim-1.0.jar",
      "lib/gson-2.3.1.jar",
      "lib/corenlp/protobuf.jar",
      "lib/berkeleyaligner.jar"
    ).mkString(":")
  List("src/naturalli_preprocess.jar", JAVANLP, CUSTOM).mkString(":")
}
