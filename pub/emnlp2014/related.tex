\Section{related}{Related Work}
% -- OpenIE
% UW
A large body of work is devoted to compiling open-domain knowledge
  bases.
For instance, OpenIE systems
  \cite{key:2007yates-textrunner,key:2011fader-reverb,key:2012mausam-ollie}
  extract concise facts via surface or dependency patterns.
% NELL
In a similar vein, NELL \cite{key:2010carlson-nell,key:2013gardnerpra-nell}
  continuously learns new high-precision facts from the internet.
% ConceptNet
The MIT Media Lab's \sys{ConceptNet} project
  \cite{key:2004liu-conceptnet}
  has been working on creating a large knowledge base emphasizing
  common sense facts.

% -- Extending OpenIE
% (people extending OpenIE)
A natural alternative to the approach taken in this paper is to
  extend knowledge bases by inferring and adding new facts directly.
% (misc)
For instance,
  \newcite{key:2006snow-wordnet} present an approach to enriching 
    the \sys{WordNet} taxonomy;
  \newcite{key:2011tandon-conceptnet} extend \sys{ConceptNet} with new facts;
  \newcite{key:2010soderland-adapting} use \sys{ReVerb} extractions to 
    enrich a domain-specific ontology.
% Richard
\newcite{key:2013chen-completion} and \newcite{key:2013socher-completion}
  use Neural Tensor Networks to predict unseen relation triples in
  WordNet and Freebase.
This work runs inference over arbitrary text, without restricting itself
  to a particular set of relations, or even entities.
% Universal schemas
\newcite{key:2012yao-schemas} and \newcite{key:2013riedel-schemas}
  present a related line of work, inferring new relations between
  Freebase entities by appealing to inferences over both Freebase and
  OpenIE relations.
This work, however, focuses primarily on common-sense reasoning rather
  than inferring relations between named entities.


% -- GOFAI
% (intro)
The goal of tacking common-sense reasoning is by no means novel in
  itself.
Work such as \newcite{key:1980reiter-logic,key:1980mccarthy-circumscription}
  attempt to reason about the truth of a consequent
  in the absence of strict logical entailment.
Similarly, \newcite{key:1989pearl-probabilistic} presents a framework for
  assigning confidences to inferences which can be reasonably assumed.
Our approach differs from these attempts in part in its use of Natural Logic
  as the underlying inference engine, and more substantially in its
  attempt at creating a truly broad-coverage system dealing with
  millions of candidate antecedents.

% -- Applications
Many NLP applications query large knowledge bases.
Prominent examples include
  question answering
    \cite{key:2001voorhees-trec},
  semantic parsing
    \cite{key:1996zelle-semantics,key:2007zettlemoyer-semantics,key:2013kwiatkowski-semantics,key:2014berant-semantics},
  information extraction
    \cite{key:2011hoffman-kbp,key:2012surdeanu-mimlre},
  and recognizing textual entailment
    \cite{key:2010-schoenmackers-horn,key:2011berant-entailment}.
A long-term goal of this work is to improve accuracy on these
  downstream tasks by providing a \textit{probabilistic} knowledge base
  over both explicitly known and likely true facts.

% Paraphrase-based Q/A
\newcite{key:2014fader-openqa} propose a system for question answering
  based on a sequence of paraphrase rewrites followed by a fuzzy query to
  a structured knowledge base.
This work can be thought of as an elegant framework for unifying this
  two-stage process, while explicitly tracking the ``risk'' taken with
  each paraphrase step.

  
