\Section{inference}{Inference As Search}
%In a classical inference setting, a system is provided both the
%  query consequent, and a set of antecedents from which to derive
%  the validity of the consequent.
%Prior work on inference with Natural Logic has assumed this scenario
%  \cite{key:2008maccartney-natlog}, and taken the two-step of approach
%  of aligning the antecedent and consequent, and classifying each
%  aligned segment into a mutation relation.
For common-sense reasoning, we are not given a well-defined
  antecedent, but rather have at our disposal a large database of
  true facts.
This makes the align-and-classify approach of 
  \refsec{maccartney-proof} substantially
  less appealing, as candidate antecedents are not readily available.

We therefore approach the problem as a search task: given the
  consequent (the query), we search over the space of possible facts for
  a valid antecedent in our database.
The nodes in our search problem correspond to candidate facts; the
  edges are mutations of these facts; the costs over these edges encode
  the confidence (or likelihood) that this edge
  maintains maintains an informative inference.

We define the problem by specifying the state space,
  the valid transitions, along with the weights of
  the transitions.
We then describe how these weights translate to the confidence of truth
  of a fact, and show that our search is at worst a generalization of
  JC distance \cite{key:1997jc-similarity} -- a common WordNet similarity
  metric.

%
% Node
%
\Subsection{inference-state}{Nodes}
The space of possible nodes in our search is the space of possible
  states in a derivation.
To a first approximation, a node is a pair $(w, s)$ of a surface form
  $w$ tagged with word sense and polarity,
  and an inference state $s$ in our collapsed FSA (\reffig{fsa}b).
In addition to this minimal information, a node in our search keeps
  track of some additional information to handle various details.

%That is, a node is primarily parametrized primarily by the surface
%  form of the candidate fact at this point in the (reverse) derivation.
%
%This surface form is augmented with both sense and polarity
%  information.
%Each word is allowed a sense (up to 31 possible senses), or a default
%  sense; in addition, 2 bits are reserved for marking polarity
%  (monotone, antitone, non-monotone).
%This leaves sufficient space to store each augmented word in a 32 bit
%  integer.
%Note also that we refer to potentially arbitrary lexical items in
%  WordNet as words -- for instance, \textit{fire truck} is treated as
%  a single word.

\paragraph{Lexical mutations}
As per our definition, transitions between nodes are transitions 
  between facts.
However, the lexical resources for the mutations are over lexical items
  (e.g., \textit{feline} $\reverse$ \textit{cat}) rather than
  entire facts.
This motivates the inclusion of an index $i$ in our node, denoting the
  index of the item which may be mutated.
Importantly, this also imposes a natural ordering of items to
  mutate, making search more efficient at the expense of rare
  search errors.
%The mutation index is allowed to shift forwards through the
%  fact (at no cost), but not backwards.
%This helps make search more tractable, at the expense of rare
%  esoteric search errors.


\paragraph{Predicting deletions}
Although inserting lexical items in a derivation (deleting words from
  the reversed derivation) is trivial, the other direction is not.
For brevity, we refer to a deletion in the derivation as an insertion,
  as from the perspective of the search algorithm constructing a reverse
  derivation, we are inserting lexical items.
\naive ly, at every node in our search, we must consider every item in
  the vocabulary as a possible insertion.

This is largely handled by storing the database of known facts as a
  trie.
Since search mutates the fact left-to-right (as per above), we can
  look up completions in the trie to use as candidate insertions.
To illustrate, given a search state with fact $w_0,w_1,\dots,w_n$
  and mutation index $i$, we would look up completions $w_{i+1}$ for
  $w_0,w_1,\dots,w_i$ in our trie of known facts.

Although this approach works well when $i$ is relatively large, there
  are likely many candidate insertions for small $i$.
We special case the most extreme case for this, where $i=0$; that is, 
  when we are inserting into the beginning of the fact.
In this case, rather than taking all possible lexical items that start
  any fact, we take all items which are followed by the first word of
  our current fact.
For instance, given a search state with fact $w_0,w_1,\dots,w_n$,
  we would propose candidate insertions $w_{-1}$ such that
  $w_{-1},w_0,w^\prime_1,\dots,w^\prime_k$ is a known fact,
  for some $w^\prime_1,\dots,w^\prime_k$.
  
%Since we are constructing antecedents left-to-right, as per above,
%  we can propose candidate deletable words from the Trie, looking up
%  the partial derivation up to the mutation index.
%As a special case, when proposing words for the beginning of the
%  fact, we take all facts whose second word matches the first word
%  of the search node.
%
%\paragraph{Tracking inference state}
%The cost of an inference at any given node depends not only on the
%  polarity of the lexical item, but also the state of the derivation
%  so far.
%We therefore augment a fact with whether the derivation is in a
%  \textit{valid} or \textit{invalid} state

\paragraph{Polarity tracking}
Mutating quantifiers can change the polarity information on a span
  in the fact.
Since we do not have the full parse tree at our disposal at search,
  we track a small amount of metadata to guess the scope of the
  mutated quantifier.

%
% TRANSITIONS
%
\Subsection{inference-transitions}{Transitions}
We begin by introducing some terminology.
A \textit{transition template} is a broad class of transitions; for
  instance WordNet hypernymy.
A \textit{transition} or \textit{transition instance} is a particular
  instantiation of a transition template.
For example, the transition from \textit{cat} to \textit{feline}.
Lastly, an \textit{edge} in the search space connects two facts, which
  are separated by a single transition instance.
For example, an edge exists between 
  \textit{some cats have tails} and \textit{some felines have tails}.

Note that the edges in the search are not constructed \textit{a priori}.
It is sufficient to store the transitions, and construct particular
  edges on demand.
At a high level, we include most relations in WordNet as transitions,
  and parametrize insertions and deletions by the part of speech
  of the token being inserted/deleted.
The full table of transitions is given in \reftab{transitions}, along
  with the relation that transition introduces, and an example edge
  in our derivation corresponding to that transition.

\begin{table*}
\begin{center}
  \begin{tabular}{lcl}
    \textbf{Template} & \textbf{Relation} & \textbf{Example edge} \\
    \hline
    WordNet hypernym                     & \forward    & \textit{some cats like milk} \forward\ \textit{some felines like milk} \\
    WordNet hyponym                      & \reverse    & \textit{some felines like milk} \reverse\ \textit{some cats like milk} \\
    WordNet antonym$^\dagger$            & \alternate  & \textit{all cats like milk} \alternate\ \textit{all cats hate milk} \\
    WordNet synonym/pertainym$^\dagger$  & \equivalent & \textit{some cats like milk} \equivalent\ \textit{some cats enjoy milk} \\
    Distributional nearest neighbor      & \equivalent & \textit{some cats like milk} \equivalent\ \textit{some cats like dairy} \\
    Delete word$^\dagger$                & \forward    & \textit{some tabby cats like milk} \forward\ \textit{some cats like milk} \\
    Add word$^\dagger$                   & \reverse    & \textit{some cats like milk} \reverse\ \textit{some tabby cats like milk} \\
    Quantifier weaken                    & \forward    & \textit{all cats like milk} \forward\ \textit{some cats like milk} \\
    Quantifier strengthen                 & \reverse    & \textit{some cats like milk} \reverse\ \textit{all felines like milk} \\
    Quantifier negate                     & \negate     & \textit{some cats like milk} \negate\ \textit{no felines like milk} \\
    Quantifier synonym                    & \equivalent & \textit{some cats like milk} \equivalent\ \textit{a few cats like milk} \\
    Change word sense                    & \equivalent & 
  \end{tabular}
	\caption{
    The edges allowed during inference.
    Entries with a dagger are parametrized by their part-of-speech
      tag, from the restricted list of $\{$noun$,$adjective$,$verb$,$other$\}$.
    The first column describes the type of the transition.
    The set-theoretic relation introduced by each relation is given in
      the second column.
    The third column gives an example of the transition in practice,
      as an edge in the search graph.
		\label{tab:transitions}
	}
\end{center}
\end{table*}

It should be noted that the mapping from transitions to relation
  types is intentionally imprecise.
For instance, clearly nearest neighbors do not preserve equivalence
  (\equivalent); more subtly, while
  \textit{all cats like milk} \alternate\ \textit{all cats hate milk},
  it is not the case that
  \textit{some cats like milk} \alternate\ \textit{some cats hate milk}.\footnote{
    The latter example is a consequence of the projection table in
    \reftab{projectivity} being overly optimistic.
  }
We mitigate this imprecision by introducing a cost for each transition,
  and learning the appropriate value for this cost
  (see \refsec{learning}).

The cost of an edge is parametrized by two values; the cost of an edge
  from fact $(f,v,p)$ with surface form $f$, validity
  $v$ and polarity $p$ to a new fact $(f',v',p')$ using a transition
  instance $t_i$ of type $t$ is given by
  $f_{t_i} \cdot \theta_{t,v,p}$, where:

\begin{itemize}
  \indentitem\item[$f_{t_i}$:]
    A value associated with every transition instance $t_i$, intuitively
      corresponding to how ``far'' the endpoints of a mutation are.
  \indentitem\item[$\theta_{t,v,p}$:]
    A learned cost for taking a transition of type $t$, if the source
    of the edge is in a validity state of $v$ and the word being mutated
    has polarity $p$.
\end{itemize}

The notation for $f_{t_i}$ is chosen to evoke an analogy to features,
  and we will refer to this quantity as the feature value.
We set $f_{t_i}$ to be 1\ in most cases;
  the exception are the edges over the WordNet hypernym tree,
  and the nearest neighbors edges.
In the first case, we take $\uparrow_{w \rightarrow w'}$ as transitioning
  from word $w$ to its hypernym $w'$ (and vice versa for
  $\downarrow_{w \rightarrow w'}$), and set:

\begin{align*}
  f_{\uparrow_{w \rightarrow w'}}   &= \log \frac{p(w')}{p(w)} &= \log p(w') - \log p(w) \\
  f_{\downarrow_{w \rightarrow w'}} &= \log \frac{p(w)}{p(w')} &= \log p(w) - \log p(w')
\end{align*}

We define $p(w)$ to be the probability (normalized frequency)
  of a word or any of its hyponyms in the Google N-Grams corpus
  \cite{key:2006brants-ngrams}.
Intuitively, this ensures that relatively long paths through fine-grained
  sections of WordNet are not unduly penalized.
For instance, the path from \textit{cat} to \textit{animal} traverses
  six intermediate nodes, \naive ly yielding a prohibitive
  search depth of 6.

For nearest neighbors edges, we take Neural Network embeddings learned
  in \newcite{key:huang-vectors} corresponding to each vocabulary entry.
We then define $f_{NN_{w \rightarrow w'}}$
  to be the arc cosine of the cosine similarity between word vectors
  associated with lexical items $w$ and $w'$:

\begin{equation*}
  f_{NN_{w \rightarrow w'}}
    = \textrm{arccos} \left( \frac{w \cdot w'}{\|w\| \|w'\|} \right)
\end{equation*}

The set of features which fire along a path
  can be expressed as a vector $\bef$.
Each element of $\bef$ corresponds to the sum of the values of that
  feature along the path.
Correspondingly, we define the weight vector $\btheta$ as the
  weight for every element of $\bef$.
The cost of a path can then be expressed as the dot product:
  $\theta \cdot \bef$.

%
% Generalize JC
%
\Subsection{inference-jc}{Generalizing Similarities}
An elegant property of our definitions of $f_{t_i}$ is its ability to
  generalize JC distance, and upper-bound distributional similarity.
Let us assume we have words $w_1$ and $w_2$, with a least common subsumer $\textrm{lcs}$.
The JC distance $\textrm{dist}_{\textrm{jc}}(w_1, w_2)$ is:

\begin{equation}
\textrm{dist}_{\textrm{jc}}(w_1, w_2)
  = \log\frac{p(\textrm{lcs})^2}{p(w_1)p(w_2)}
\label{eqn:jc}
\end{equation}

For simplicity, we simplify $\theta_{\uparrow,v,p}$ and $\theta_{\uparrow,v,p}$
  as simply $\theta_\uparrow$ and $\theta_\downarrow$.
The derivation generalizes trivially to the the case where weights are
  further parametrized.
Without loss of generality, we also assume that a path in our search
  is only modifying a single word $w_1$, ending at a mutation of the
  word $w_2$.

We can factorize the cost of a path, $\theta \cdot \bef$, along the path
  from $w_1$ to $w_2$ through its lowest common subsumer (lcs),
  $[w_1, w_1^{(1)}, \dots, \textrm{lcs}, \dots,  w_2^{(1)}, w_2]$,
  as follows:

\begin{align*}
\theta \cdot \phi
  &= \theta_\uparrow \left( 
    \left[\log p(w_1^{(1)}) - \log p(w_1)\right] +
    \dots
%   + \left[\log p(w_1^{(n)}) - \log p(\textrm{lcs})\right]
    \right) + \\
  &~~~~~~ \theta_\downarrow \left( 
    \left[\log p(\textrm{lcs}) - \log p(w_1^{(n)}) \right] +
    \dots
%    + \left[\log p(w_1) - \log p(w_1^{(1)})\right]
    \right) \\
  &= \theta_\uparrow \left( \log \frac{p(\textrm{lcs})}{p(w_1)} \right) +
     \theta_\downarrow \left( \log \frac{p(\textrm{lcs})}{p(w_2)} \right) \\
  &= \log \frac{ p(\textrm{lcs})^{\theta_\uparrow + \theta_\downarrow} }
               { p(w_1)^{\theta_\uparrow} + p(w_2)^{\theta_\downarrow} }
\end{align*}

Note that setting both $\theta_\uparrow$ and $\theta_\downarrow$ to 1 exactly
  yield the Formula \refeqn{jc} for JC distance.

It is also worth noting that the nearest neighbors path provides an
  upper bound on the true similarity between the start and end words
  in the path.
In this way, the search based approach presented here can be thought
  of as generalizing and formalizing the intuition that similar objects 
  have similar properties (e.g., as presented in
  \newcite{key:2013angeli-truth}) using both common classes of similarity
  metrics.

%
% PROBABILITY
%
\Subsection{inference-prob}{Confidence Estimation}
The last component in inference is translating a search path into a
  probability of truth.
We notice from \refsec{inference-transitions} that the \textit{cost}
  of a path can be represented as $\btheta \cdot \bef$.
We can normalize this value by negating every element of the weight
  vector and passing it through a sigmoid:

\begin{equation*}
\textrm{confidence} = \frac{1}{1 + e^{\theta \cdot \bef}}
\end{equation*}

Importantly, note that the cost vector must be non-negative for the
  search to be well-defined, and therefore the confidence value will
  be constrained to be between 0 and $\frac{1}{2}$.

At this point, we have a confidence that the given path has not violated
  strict Natural Logic.
However, to translate this value into a probability
  we need to incorporate whether the inference path is
  confidently valid, or confidently invalid.
To illustrate, a fact with a low confidence should translate to a
  probability of $\frac{1}{2}$, rather than a probability of 0.

We therefore define the probability of validity as follows.
We take $v$ to be 1 if the final fact of our derivation is in the
  \textit{valid} state with respect to the antecedent,
  and -1 if this fact is in the \textit{invalid} state.
In practice, as our search is reversed, we take the state of the
  antecedent in our database when compared to the consequent, rather
  than vice versa.
For completeness, if no path is given we can set $v=0$.
The probability of validity then becomes:

\begin{equation}
  p(\textrm{valid}) = \frac{v}{2} + \frac{1}{1 + e^{v \theta \cdot \bef}}
  \label{eqn:prob}
\end{equation}

Note that in the case where $v=-1$, the above expression reduces to
  $\frac{1}{2} - \textrm{confidence}$; in the case where $v=0$ it
  reduces to simply $\frac{1}{2}$.
Furthermore, note that the probability of truth makes use of the same
  parameters as the cost in the search.
Thus, as better weights are learned, the search is likewise more likely
  to produce derivations which would confidently support or disprove the
  query.
We proceed to describe how these weights are learned.
