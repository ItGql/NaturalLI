\Section{intro}{Introduction}
% Tradeoff between logic and lexical methods
A central challenge for textual entailment is finding an optimal trade-off between
  \textit{high-precision} strict logical reasoning, and \textit{broad coverage}
  lexical methods.
For example, consider the following hypothesis (H) and associated supporting premise (P):

% Example: hard for logic, easy for lexical
\entailmentExample
{Ovaries are the female part of the flower, which produces eggs that are needed for making seeds.}
{A flower produces the seeds.}

% Explain example; lexical methods often good.
To prove the hypothesis from the premise in a satisfactory way, you would need
  to traverse a large number of nontrivial inference steps.
In contrast, even a simple lexical overlap classifier could correctly predict
  the entailment.
In fact, such a bag-of-words entailment model has been shown to be surprisingly
  effective on the Recognizing Textual Entailment (RTE) challenges 
  \cite{key:2009maccartney-thesis}.

% Why we want logic anyways
These lexical methods are notorious for ignoring even trivial cases of nonentailment,
  e.g., recognizing negation.
For example, the following pair has a near perfect lexical overlap, but in fact defines
  an explicit contradiction:

% Example: hard for lexical, easy for logic.
\entailmentExample
{Eating candy for dinner is an example of a poor health habit.}
{Eating candy is an example of a good health habit.}

% Switch focus to IR / QA
In many cases -- most prominently, question answering (QA) -- our task is not to predict
  an entailment between a single pair of sentences, but rather to find any
  supporting sentence for a query in a large corpus of text.
Information retrieval approaches can be viewed as the question answering analogue 
  of lexical overlap classifiers for entailment.
From the other side, systems like OQA \cite{key:2014fader-openqa} or
  NaturalLI \cite{key:2014angeli-naturalli} use a soft logical inference to
  find explicit support for the query in the text.

% Our Goal
This paper presents an approach to QA which combines the advantages of both
  frameworks.
We train a classifier to predict entailment of a query given a premise returned
  from an information retrieval (IR) system.
We additionally present improvements to NaturalLI to accommodate
  longer sentences and more complex entailments.
We then answer a query by running both systems, allowing NaturalLI to either
  (1) answer the question on its own; (2) veto the judgment of the lexical
  classifier, or (3) provide soft evidence for the truth or falsehood of the
  query based on the results from IR.

% Natural Logic
NaturalLI makes use of Natural Logic \cite{key:1986benthem-natlog,key:1991valencia-natlog}
  to infer the truth of a query from an arbitrary set of plain-text premises.
Natural logic is a logical formalism which captures a range of common logical
  inferences within the syntax of natural language itself;
  that is, without appealing to a synthetic logical syntax and proof system.
This is a natural choice for our task, as it allows the two halves of our system
  to speak the same language in a sense -- both systems use the same underlying
  corpus, and can represent soft entailments using the same features.
%In much the same vein as \newcite{key:2008maccartney-natlog} and
%  \newcite{key:2009maccartney-natlog}, this allows us to 

% Contributions
We present the following contributions:
(1) we extend NaturalLI to perform better over long, real-world sentences by
  operating over dependency trees, and incorporating meronymy and relational
  entailment;
(2) we show that NaturalLI can be used to correct difficult entailment decisions
  made by a lexical classifier; and
(3) we present the best published numbers on a question answering dataset
  consisting of fourth grade science questions.


