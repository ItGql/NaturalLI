\Section{related}{Related Work}
% Talk about OpenIE
There is a large body of work on open information extraction.
One line of work begins with
  TextRunner \cite{key:2007yates-textrunner} and
  ReVerb \cite{key:2011fader-reverb}, which make use of computationally
  efficient surface patterns over tokens.
With the introduction of fast dependency parsers,
  Ollie \cite{key:2012mausam-ollie} continues in the same spirit but with
  learned dependency patterns, improving on the earlier WOE system
  \cite{key:2010wu-openie}.
The Never Ending Language Learning project \cite{key:2010carlson-nell}
  has a similar aim, iteratively learning more facts from the internet
  from a seed set of examples.
Exemplar \cite{key:2013mesquita-exemplar} adapts the open IE framework to
  $n$-ary relationships similar to semantic role labeling, but without the
  expensive machinery.

% Uses of Open IE
Open IE triples have been used in a number of applications --
  for example, learning entailment graphs for new triples
  \cite{key:2011berant-entailment}, and
  matrix factorization for unifying open IE and structured relations
  \cite{key:2012yao-schemas,key:2013riedel-schemas}.
In each of these cases, the concise extractions provided by open IE allow
  for efficient symbolic methods for entailment, such as Markov logic
  networks or matrix factorization.

% Talk about relation extraction
Prior work on the KBP challenge can be categorized into a number of approaches.
The most common of these are \textit{distantly supervised} relation extractors
  \cite{key:1999craven-distsup,key:2007wu-distsup,key:2009mintz-distsup,key:2011sun-kbp},
  and rule based systems
  \cite{key:1997soderland-kbp,key:2010grishman-kbp,key:2010chen-kbp}.
However, both of these approaches require careful tuning to the task, and
  need to be trained explicitly on the KBP relation schema.
\newcite{key:2013soderland-kbp} submitted a system to KBP making use of
  open IE relations and an easily constructed mapping to KBP relations;
  we use this as a baseline for our empirical evaluation.

% Natural Logic
Prior work has used natural logic
  for RTE-style textual entailment,
  as a formalism well-suited for formal semantics in neural networks,
  and as a framework for common-sense reasoning
  \cite{key:2009maccartney-natlog,key:2012watanabe-natlog,key:2014bowman-natlog,key:2014angeli-naturalli}.
We adopt the precise semantics of \newcite{key:2014icard-natlog}.
Our approach of finding short entailments from a longer utterance is similar
  in spirit to work on textual entailment for information extraction
  \cite{key:2006romano-ie}.

