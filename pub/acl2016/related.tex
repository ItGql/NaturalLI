\Section{related}{Related Work}
% -- RTE
This work is similar in many ways to work on 
  recognizing textual entailment -- e.g., 
  \newcite{key:2010-schoenmackers-horn}, \newcite{key:2011berant-entailment},
  \newcite{key:2013lewis-entailment}.
In the RTE task, a single premise and a single hypothesis are given as input,
  and a system must return a judgment of either \textit{entailment} or
  \textit{nonentailment} (in later years, \textit{nonentailment} is further
  split into contradiction and independence).
These approaches often rely on alignment features, similar to ours, but
  do not generally scale to large premise sets (i.e., a comprehensive
  knowledge base).
The discourse commitments in \newcite{key:2007hickl-rte} can be thought
  of as similar to the additional entailed facts we add to the
  knowledge base (\refsec{naturalli-forward}).
In another line of work, \newcite{key:2014tian-dcs} approach the RTE problem
  by parsing into Dependency Compositional Semantics (DCS)
  \cite{key:2011liang-semantics}.
This work  particularly relevant in that it also incorporates an evaluation
  function (using distributional similarity) to augment their theorem prover --
  although in their case, this requires a translation back and forth between
  DCS and language.
\newcite{key:2016beltagy-logic} takes a similar approach, but encoding
  distributional information directly in entailment rules in a Markov Logic
  Network \cite{key:2006richardson-mln}.

% -- Q/A
Many systems make use of structured knowledge bases for question
  answering.
Semantic parsing methods 
  \cite{key:2005zettlemoyer-semantics,key:2011liang-semantics}
  use knowledge bases like Freebase to find support for a
  complex question.
% Richard
Knowledge base completion 
  (e.g., \newcite{key:2013chen-completion}, \newcite{key:2011bordes-completion},
  or \newcite{key:2013riedel-schemas}) can be thought of as entailment,
  predicting novel knowledge base entries from the original database.
%  can be like
%  use Neural Tensor Networks to predict unseen relation triples in
%  WordNet and Freebase, following a line of work by
%  \newcite{key:2011bordes-completion} and
%  \newcite{key:2012jenatton-completion}.
%% Universal schemas
%\newcite{key:2012yao-schemas} and \newcite{key:2013riedel-schemas}
%  present a related line of work, inferring new relations between
%  Freebase entities via inference over both Freebase and
%  OpenIE relations.
In contrast, this work runs inference over arbitrary text without
  needing a structured knowledge base.
% Paraphrase-based Q/A
Open IE \cite{key:2010wu-openie,key:2012mausam-ollie}
  QA approaches -- e.g., \newcite{key:2014fader-openqa}
  are closer to operating over plain text, but
  still requires structured extractions.
%\newcite{key:2014fader-openqa} perform question answering by following
%  fuzzy rewrites over a question to find support in a knowledge base
%  of open IE extractions.

% -- Logic-based QA
Of course, this work is not alone in attempting to incorporate
  strict logical reasoning into question answering systems.
The COGEX system \cite{key:2003moldovan-trec} incorporates a theorem
  prover into a QA system, boosting overall performance on the TREC
  QA task.
Similarly, Watson \cite{key:2010ferrucci-watson} incorporates
  logical reasoning components alongside shallower methods.
This work follows a similar vein, but both the theorem prover
  and lexical classifier operate over text, without requiring either
  the premises or axioms to be in logical forms.
  

% -- Aristo
% Dialog
On the Aristo corpus we evaluate on, \newcite{key:2015hixon-aristo} proposes
  a dialog system to augment a knowledge graph used for answering the questions.
This is in a sense an oracle measure, where a human is consulted while answering
  the question; although, they show that their additional extractions help
  answer questions other than the one the dialog was collected for.



